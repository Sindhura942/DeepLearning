Deep Learning Projects

ğŸš€ Overview

A collection of three end-to-end deep learning projects built using TensorFlow/Keras, solving real-world problems in classification and regression.

ğŸŒŸ Projects Overview

Project

Type

Dataset

Metrics

Output Highlights

Customer Churn Prediction

Classification

Telco Dataset

Accuracy, Loss

âœ… Test Accuracy: 79.46%

Housing Price Prediction

Regression

Housing Dataset

MSE, MAE, RMSE, RÂ²

âœ… Test MSE: 0.2529, Test MAE: 0.3329, RÂ²: 0.9993

Employee Salary Prediction

Regression

Employee Dataset

RMSE, MAE, MAPE, RÂ²

âœ… RMSE: $647.85, MAE: $584.32, RÂ²: 0.9993

1ï¸âƒ£ Customer Churn Prediction

Objective: Predict whether a customer will churn based on demographics and service usage.

Model Highlights:

ANN with ReLU activations

Dropout for regularization

Sigmoid output for binary classification

Performance:

Best Epoch: 39 (Early stopping at 44)

Training Accuracy: ~80%

Validation Accuracy: ~81%

Test Accuracy: 79.46% âœ…

2ï¸âƒ£ Housing Price Prediction

Objective: Predict house prices using numerical features.

Model Highlights:

Dense layers with ReLU activations

Linear output layer for regression

Performance:

Test MSE: 0.2529

Test MAE: 0.3329

RÂ² Score: 0.9993 âœ…

3ï¸âƒ£ Employee Salary Prediction

Objective: Predict employee salaries based on experience, education, and other factors.

Model Highlights:

Dense layers with ReLU activations

Linear output layer

Performance:

RMSE: $647.85

MAE: $584.32

MAPE: 0.64%

RÂ² Score: 0.9993 âœ…

ğŸ›  Tech Stack

Python ğŸ

TensorFlow / Keras ğŸ¤–

Scikit-learn ğŸ”§

Pandas & NumPy ğŸ“Š

Matplotlib / Seaborn ğŸ¨

ğŸ“ˆ Key Learnings

Built ANN models for both classification and regression tasks.

Applied early stopping, dropout, and feature scaling to improve performance.

Learned to handle real-world datasets with preprocessing, encoding, and evaluation.

Achieved high accuracy and very low error metrics.

ğŸ“‚ Dataset Links

Telco Customer Churn: Kaggle

Housing Price Dataset: Kaggle

Employee Salary Dataset: 
